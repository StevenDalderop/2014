{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3: Prediction and Classification\n",
    "\n",
    "Due: Thursday, October 16, 2014 11:59 PM\n",
    "\n",
    "<a href=https://raw.githubusercontent.com/cs109/2014/master/homework/HW3.ipynb download=HW3.ipynb> Download this assignment</a>\n",
    "\n",
    "#### Submission Instructions\n",
    "To submit your homework, create a folder named lastname_firstinitial_hw# and place your IPython notebooks, data files, and any other files in this folder. Your IPython Notebooks should be completely executed with the results visible in the notebook. We should not have to run any code. Compress the folder (please use .zip compression) and submit to the CS109 dropbox in the appropriate folder. If we cannot access your work because these directions are not followed correctly, we will not grade your work.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In this assignment you will be using regression and classification to explore different data sets.  \n",
    "\n",
    "**First**: You will use data from before 2002 in the [Sean Lahman's Baseball Database](http://seanlahman.com/baseball-archive/statistics) to create a metric for picking baseball players using linear regression. This is same database we used in Homework 1. This database contains the \"complete batting and pitching statistics from 1871 to 2013, plus fielding statistics, standings, team stats, managerial records, post-season data, and more\". [Documentation provided here](http://seanlahman.com/files/database/readme2012.txt).\n",
    "\n",
    "![\"Sabermetrics Science\"](http://saberseminar.com/wp-content/uploads/2012/01/saber-web.jpg)\n",
    "http://saberseminar.com/wp-content/uploads/2012/01/saber-web.jpg\n",
    "\n",
    "**Second**: You will use the famous [iris](http://en.wikipedia.org/wiki/Iris_flower_data_set) data set to perform a $k$-neareast neighbor classification using cross validation.  While it was introduced in 1936, it is still [one of the most popular](http://archive.ics.uci.edu/ml/) example data sets in the machine learning community. Wikipedia describes the data set as follows: \"The data set consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres.\" Here is an illustration what the four features measure:\n",
    "\n",
    "![\"iris data features\"](http://sebastianraschka.com/Images/2014_python_lda/iris_petal_sepal.png)\n",
    "http://sebastianraschka.com/Images/2014_python_lda/iris_petal_sepal.png\n",
    "\n",
    "**Third**: You will investigate the influence of higher dimensional spaces on the classification using another standard data set in machine learning called the The [digits data set](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html).  This data set is similar to the MNIST data set discussed in the lecture. The main difference is, that each digit is represented by an 8x8 pixel image patch, which is considerably smaller than the 28x28 pixels from MNIST. In addition, the gray values are restricted to 16 different values (4 bit), instead of 256 (8 bit) for MNIST. \n",
    "\n",
    "**Finally**: In preparation for Homework 4, we want you to read through the following articles related to predicting the 2014 Senate Midterm Elections. \n",
    "\n",
    "* [Nate Silver's Methodology at while at NYT](http://fivethirtyeight.blogs.nytimes.com/methodology/)\n",
    "* [How The FiveThirtyEight Senate Forecast Model Works](http://fivethirtyeight.com/features/how-the-fivethirtyeight-senate-forecast-model-works/)\n",
    "* [Pollster Ratings v4.0: Methodology](http://fivethirtyeight.com/features/pollster-ratings-v40-methodology/)\n",
    "* [Pollster Ratings v4.0: Results](http://fivethirtyeight.com/features/pollster-ratings-v40-results/)\n",
    "* [Nate Silver versus Sam Wang](http://www.washingtonpost.com/blogs/plum-line/wp/2014/09/17/nate-silver-versus-sam-wang/)\n",
    "* [More Nate Silver versus Sam Wang](http://www.dailykos.com/story/2014/09/09/1328288/-Get-Ready-To-Rumbllllle-Battle-Of-The-Nerds-Nate-Silver-VS-Sam-Wang)\n",
    "* [Nate Silver explains critisims of Sam Wang](http://politicalwire.com/archives/2014/10/02/nate_silver_rebuts_sam_wang.html)\n",
    "* [Background on the feud between Nate Silver and Sam Wang](http://talkingpointsmemo.com/dc/nate-silver-sam-wang-feud)\n",
    "* [Are there swing voters?]( http://www.stat.columbia.edu/~gelman/research/unpublished/swing_voters.pdf)\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nimport sklearn\\nimport sklearn.datasets\\nimport sklearn.cross_validation\\nimport sklearn.decomposition\\nimport sklearn.grid_search\\nimport sklearn.neighbors\\nimport sklearn.metrics\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# special IPython command to prepare the notebook for matplotlib\n",
    "%matplotlib inline \n",
    "\n",
    "import requests \n",
    "import StringIO\n",
    "import zipfile\n",
    "#import numpy as np\n",
    "import pandas as pd # pandas\n",
    "#import matplotlib.pyplot as plt # module for plotting \n",
    "\n",
    "# If this module is not already installed, you may need to install it. \n",
    "# You can do this by typing 'pip install seaborn' in the command line\n",
    "#import seaborn as sns \n",
    "\"\"\"\n",
    "import sklearn\n",
    "import sklearn.datasets\n",
    "import sklearn.cross_validation\n",
    "import sklearn.decomposition\n",
    "import sklearn.grid_search\n",
    "import sklearn.neighbors\n",
    "import sklearn.metrics\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Sabermetrics\n",
    "\n",
    "Using data preceding the 2002 season pick 10 offensive players keeping the payroll under $20 million (assign each player the median salary). Predict how many games this team would win in a 162 game season.  \n",
    "\n",
    "In this problem we will be returning to the [Sean Lahman's Baseball Database](http://seanlahman.com/baseball-archive/statistics) that we used in Homework 1.  From this database, we will be extract five data sets containing information such as yearly stats and standing, batting statistics, fielding statistics, player names, player salaries and biographical information. You will explore the data in this database from before 2002 and create a metric for picking players. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(a) \n",
    "\n",
    "Load in [these CSV files](http://seanlahman.com/files/database/lahman-csv_2014-02-14.zip) from the [Sean Lahman's Baseball Database](http://seanlahman.com/baseball-archive/statistics). For this assignment, we will use the 'Teams.csv', 'Batting.csv', 'Salaries.csv', 'Fielding.csv', 'Master.csv' tables. Read these tables into separate pandas DataFrames with the following names. \n",
    "\n",
    "CSV file name | Name of pandas DataFrame\n",
    ":---: | :---: \n",
    "Teams.csv | teams\n",
    "Batting.csv | players\n",
    "Salaries.csv | salaries\n",
    "Fielding.csv | fielding\n",
    "Master.csv | master"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://seanlahman.com/files/database/lahman-csv_2014-02-14.zip\"\n",
    "source = requests.get(url)\n",
    "r=source.content\n",
    "s = StringIO.StringIO(r)\n",
    "zf = zipfile.ZipFile(s, 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "teams=pd.read_csv(zf.open(\"Teams.csv\"))\n",
    "players=pd.read_csv(zf.open(\"Batting.csv\"))\n",
    "salaries=pd.read_csv(zf.open(\"Salaries.csv\"))\n",
    "fielding=pd.read_csv(zf.open(\"Fielding.csv\"))\n",
    "master=pd.read_csv(zf.open(\"Master.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(b)\n",
    "\n",
    "Calculate the median salary for each player and create a pandas DataFrame called `medianSalaries` with four columns: (1) the player ID, (2) the first name of the player, (3) the last name of the player and (4) the median salary of the player. Show the head of the `medianSalaries` DataFrame.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>birthYear</th>\n",
       "      <th>birthMonth</th>\n",
       "      <th>birthDay</th>\n",
       "      <th>birthCountry</th>\n",
       "      <th>birthState</th>\n",
       "      <th>birthCity</th>\n",
       "      <th>deathYear</th>\n",
       "      <th>deathMonth</th>\n",
       "      <th>deathDay</th>\n",
       "      <th>...</th>\n",
       "      <th>nameLast</th>\n",
       "      <th>nameGiven</th>\n",
       "      <th>weight</th>\n",
       "      <th>height</th>\n",
       "      <th>bats</th>\n",
       "      <th>throws</th>\n",
       "      <th>debut</th>\n",
       "      <th>finalGame</th>\n",
       "      <th>retroID</th>\n",
       "      <th>bbrefID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardsda01</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Aardsma</td>\n",
       "      <td>David Allan</td>\n",
       "      <td>205.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>2004-04-06</td>\n",
       "      <td>2013-09-28</td>\n",
       "      <td>aardd001</td>\n",
       "      <td>aardsda01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaronha01</td>\n",
       "      <td>1934.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>AL</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Henry Louis</td>\n",
       "      <td>180.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>1954-04-13</td>\n",
       "      <td>1976-10-03</td>\n",
       "      <td>aaroh101</td>\n",
       "      <td>aaronha01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaronto01</td>\n",
       "      <td>1939.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>AL</td>\n",
       "      <td>Mobile</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>Aaron</td>\n",
       "      <td>Tommie Lee</td>\n",
       "      <td>190.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>1962-04-10</td>\n",
       "      <td>1971-09-26</td>\n",
       "      <td>aarot101</td>\n",
       "      <td>aaronto01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aasedo01</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>CA</td>\n",
       "      <td>Orange</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Aase</td>\n",
       "      <td>Donald William</td>\n",
       "      <td>190.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>R</td>\n",
       "      <td>R</td>\n",
       "      <td>1977-07-26</td>\n",
       "      <td>1990-10-03</td>\n",
       "      <td>aased001</td>\n",
       "      <td>aasedo01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abadan01</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>USA</td>\n",
       "      <td>FL</td>\n",
       "      <td>Palm Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Abad</td>\n",
       "      <td>Fausto Andres</td>\n",
       "      <td>184.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>L</td>\n",
       "      <td>L</td>\n",
       "      <td>2001-09-10</td>\n",
       "      <td>2006-04-13</td>\n",
       "      <td>abada001</td>\n",
       "      <td>abadan01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    playerID  birthYear  birthMonth  birthDay birthCountry birthState  \\\n",
       "0  aardsda01     1981.0        12.0      27.0          USA         CO   \n",
       "1  aaronha01     1934.0         2.0       5.0          USA         AL   \n",
       "2  aaronto01     1939.0         8.0       5.0          USA         AL   \n",
       "3   aasedo01     1954.0         9.0       8.0          USA         CA   \n",
       "4   abadan01     1972.0         8.0      25.0          USA         FL   \n",
       "\n",
       "    birthCity  deathYear  deathMonth  deathDay    ...     nameLast  \\\n",
       "0      Denver        NaN         NaN       NaN    ...      Aardsma   \n",
       "1      Mobile        NaN         NaN       NaN    ...        Aaron   \n",
       "2      Mobile     1984.0         8.0      16.0    ...        Aaron   \n",
       "3      Orange        NaN         NaN       NaN    ...         Aase   \n",
       "4  Palm Beach        NaN         NaN       NaN    ...         Abad   \n",
       "\n",
       "        nameGiven weight height bats throws       debut   finalGame   retroID  \\\n",
       "0     David Allan  205.0   75.0    R      R  2004-04-06  2013-09-28  aardd001   \n",
       "1     Henry Louis  180.0   72.0    R      R  1954-04-13  1976-10-03  aaroh101   \n",
       "2      Tommie Lee  190.0   75.0    R      R  1962-04-10  1971-09-26  aarot101   \n",
       "3  Donald William  190.0   75.0    R      R  1977-07-26  1990-10-03  aased001   \n",
       "4   Fausto Andres  184.0   73.0    L      L  2001-09-10  2006-04-13  abada001   \n",
       "\n",
       "     bbrefID  \n",
       "0  aardsda01  \n",
       "1  aaronha01  \n",
       "2  aaronto01  \n",
       "3   aasedo01  \n",
       "4   abadan01  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianSalaries=master[[\"playerID\",\"nameGiven\",\"nameLast\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playerID</th>\n",
       "      <th>nameGiven</th>\n",
       "      <th>nameLast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aardsda01</td>\n",
       "      <td>David Allan</td>\n",
       "      <td>Aardsma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aaronha01</td>\n",
       "      <td>Henry Louis</td>\n",
       "      <td>Aaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aaronto01</td>\n",
       "      <td>Tommie Lee</td>\n",
       "      <td>Aaron</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aasedo01</td>\n",
       "      <td>Donald William</td>\n",
       "      <td>Aase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abadan01</td>\n",
       "      <td>Fausto Andres</td>\n",
       "      <td>Abad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    playerID       nameGiven nameLast\n",
       "0  aardsda01     David Allan  Aardsma\n",
       "1  aaronha01     Henry Louis    Aaron\n",
       "2  aaronto01      Tommie Lee    Aaron\n",
       "3   aasedo01  Donald William     Aase\n",
       "4   abadan01   Fausto Andres     Abad"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medianSalaries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearID</th>\n",
       "      <th>teamID</th>\n",
       "      <th>lgID</th>\n",
       "      <th>playerID</th>\n",
       "      <th>salary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>murraed02</td>\n",
       "      <td>1472819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>lynnfr01</td>\n",
       "      <td>1090000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>ripkeca01</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>lacyle01</td>\n",
       "      <td>725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>flanami01</td>\n",
       "      <td>641667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>boddimi01</td>\n",
       "      <td>625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>stewasa01</td>\n",
       "      <td>581250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>martide01</td>\n",
       "      <td>560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>roeniga01</td>\n",
       "      <td>558333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>mcgresc01</td>\n",
       "      <td>547143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>dempsri01</td>\n",
       "      <td>512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>grosswa01</td>\n",
       "      <td>483333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>dauerri01</td>\n",
       "      <td>480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>fordda01</td>\n",
       "      <td>450000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>martiti01</td>\n",
       "      <td>440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>davisst02</td>\n",
       "      <td>437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>dwyerji01</td>\n",
       "      <td>375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>nolanjo01</td>\n",
       "      <td>341667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>shelbjo01</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>rayfofl01</td>\n",
       "      <td>128500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>youngmi01</td>\n",
       "      <td>121000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1985</td>\n",
       "      <td>BAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>sheetla01</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>stanlbo01</td>\n",
       "      <td>1075000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>boggswa01</td>\n",
       "      <td>1000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>armasto01</td>\n",
       "      <td>915000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>evansdw01</td>\n",
       "      <td>800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>riceji01</td>\n",
       "      <td>779227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>bucknbi01</td>\n",
       "      <td>747500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>easlemi01</td>\n",
       "      <td>650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1985</td>\n",
       "      <td>BOS</td>\n",
       "      <td>AL</td>\n",
       "      <td>clearma01</td>\n",
       "      <td>580000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1985</td>\n",
       "      <td>CAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>sconida01</td>\n",
       "      <td>130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1985</td>\n",
       "      <td>CAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>pettiga01</td>\n",
       "      <td>125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1985</td>\n",
       "      <td>CAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>schofdi02</td>\n",
       "      <td>120000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>1985</td>\n",
       "      <td>CAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>clibust02</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>1985</td>\n",
       "      <td>CAL</td>\n",
       "      <td>AL</td>\n",
       "      <td>mccaski01</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>cruzju01</td>\n",
       "      <td>1242333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>seaveto01</td>\n",
       "      <td>1136262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>dotsori01</td>\n",
       "      <td>900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>bannifl01</td>\n",
       "      <td>811250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>burnsbr01</td>\n",
       "      <td>727500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>fiskca01</td>\n",
       "      <td>685000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>baineha01</td>\n",
       "      <td>675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>lawru01</td>\n",
       "      <td>565000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>lollati01</td>\n",
       "      <td>463000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>spillda01</td>\n",
       "      <td>390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>pacioto01</td>\n",
       "      <td>333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>salazlu01</td>\n",
       "      <td>325000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>kittlro01</td>\n",
       "      <td>300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>jamesbo01</td>\n",
       "      <td>265000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>hillma01</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>walkegr01</td>\n",
       "      <td>195000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>fletcsc01</td>\n",
       "      <td>165000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>hairsje01</td>\n",
       "      <td>150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>agostju01</td>\n",
       "      <td>147500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>nelsoge01</td>\n",
       "      <td>110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1985</td>\n",
       "      <td>CHA</td>\n",
       "      <td>AL</td>\n",
       "      <td>guilloz01</td>\n",
       "      <td>60000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>1985</td>\n",
       "      <td>CLE</td>\n",
       "      <td>AL</td>\n",
       "      <td>thornan01</td>\n",
       "      <td>1100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1985</td>\n",
       "      <td>CLE</td>\n",
       "      <td>AL</td>\n",
       "      <td>blylebe01</td>\n",
       "      <td>650000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1985</td>\n",
       "      <td>CLE</td>\n",
       "      <td>AL</td>\n",
       "      <td>hargrmi01</td>\n",
       "      <td>458333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>1985</td>\n",
       "      <td>CLE</td>\n",
       "      <td>AL</td>\n",
       "      <td>francju01</td>\n",
       "      <td>455000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    yearID teamID lgID   playerID   salary\n",
       "0     1985    BAL   AL  murraed02  1472819\n",
       "1     1985    BAL   AL   lynnfr01  1090000\n",
       "2     1985    BAL   AL  ripkeca01   800000\n",
       "3     1985    BAL   AL   lacyle01   725000\n",
       "4     1985    BAL   AL  flanami01   641667\n",
       "5     1985    BAL   AL  boddimi01   625000\n",
       "6     1985    BAL   AL  stewasa01   581250\n",
       "7     1985    BAL   AL  martide01   560000\n",
       "8     1985    BAL   AL  roeniga01   558333\n",
       "9     1985    BAL   AL  mcgresc01   547143\n",
       "10    1985    BAL   AL  dempsri01   512500\n",
       "11    1985    BAL   AL  grosswa01   483333\n",
       "12    1985    BAL   AL  dauerri01   480000\n",
       "13    1985    BAL   AL   fordda01   450000\n",
       "14    1985    BAL   AL  martiti01   440000\n",
       "15    1985    BAL   AL  davisst02   437500\n",
       "16    1985    BAL   AL  dwyerji01   375000\n",
       "17    1985    BAL   AL  nolanjo01   341667\n",
       "18    1985    BAL   AL  shelbjo01   130000\n",
       "19    1985    BAL   AL  rayfofl01   128500\n",
       "20    1985    BAL   AL  youngmi01   121000\n",
       "21    1985    BAL   AL  sheetla01    60000\n",
       "22    1985    BOS   AL  stanlbo01  1075000\n",
       "23    1985    BOS   AL  boggswa01  1000000\n",
       "24    1985    BOS   AL  armasto01   915000\n",
       "25    1985    BOS   AL  evansdw01   800000\n",
       "26    1985    BOS   AL   riceji01   779227\n",
       "27    1985    BOS   AL  bucknbi01   747500\n",
       "28    1985    BOS   AL  easlemi01   650000\n",
       "29    1985    BOS   AL  clearma01   580000\n",
       "..     ...    ...  ...        ...      ...\n",
       "70    1985    CAL   AL  sconida01   130000\n",
       "71    1985    CAL   AL  pettiga01   125000\n",
       "72    1985    CAL   AL  schofdi02   120000\n",
       "73    1985    CAL   AL  clibust02    60000\n",
       "74    1985    CAL   AL  mccaski01    60000\n",
       "75    1985    CHA   AL   cruzju01  1242333\n",
       "76    1985    CHA   AL  seaveto01  1136262\n",
       "77    1985    CHA   AL  dotsori01   900000\n",
       "78    1985    CHA   AL  bannifl01   811250\n",
       "79    1985    CHA   AL  burnsbr01   727500\n",
       "80    1985    CHA   AL   fiskca01   685000\n",
       "81    1985    CHA   AL  baineha01   675000\n",
       "82    1985    CHA   AL    lawru01   565000\n",
       "83    1985    CHA   AL  lollati01   463000\n",
       "84    1985    CHA   AL  spillda01   390000\n",
       "85    1985    CHA   AL  pacioto01   333333\n",
       "86    1985    CHA   AL  salazlu01   325000\n",
       "87    1985    CHA   AL  kittlro01   300000\n",
       "88    1985    CHA   AL  jamesbo01   265000\n",
       "89    1985    CHA   AL   hillma01   200000\n",
       "90    1985    CHA   AL  walkegr01   195000\n",
       "91    1985    CHA   AL  fletcsc01   165000\n",
       "92    1985    CHA   AL  hairsje01   150000\n",
       "93    1985    CHA   AL  agostju01   147500\n",
       "94    1985    CHA   AL  nelsoge01   110000\n",
       "95    1985    CHA   AL  guilloz01    60000\n",
       "96    1985    CLE   AL  thornan01  1100000\n",
       "97    1985    CLE   AL  blylebe01   650000\n",
       "98    1985    CLE   AL  hargrmi01   458333\n",
       "99    1985    CLE   AL  francju01   455000\n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "salaries.head(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(c)\n",
    "\n",
    "Now, consider only team/season combinations in which the teams played 162 Games. Exclude all data from before 1947. Compute the per plate appearance rates for singles, doubles, triples, HR, and BB. Create a new pandas DataFrame called `stats` that has the teamID, yearID, wins and these rates.\n",
    "\n",
    "**Hint**: Singles are hits that are not doubles, triples, nor HR. Plate appearances are base on balls plus at bats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(d)\n",
    "\n",
    "Is there a noticeable time trend in the rates computed computed in Problem 1(c)? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(e) \n",
    "\n",
    "Using the `stats` DataFrame from Problem 1(c), adjust the singles per PA rates so that the average across teams for each year is 0. Do the same for the doubles, triples, HR, and BB rates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(f)\n",
    "\n",
    "Build a simple linear regression model to predict the number of wins from the average adjusted singles, double, triples, HR, and BB rates. To decide which of these terms to include fit the model to data from 2002 and compute the average squared residuals from predictions to years past 2002. Use the fitted model to define a new sabermetric summary: offensive predicted wins (OPW). Hint: the new summary should be a linear combination of one to five of the five rates.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(g)\n",
    "\n",
    "Now we will create a similar database for individual players. Consider only player/year combinations in which the player had at least 500 plate appearances. Consider only the years we considered for the calculations above (after 1947 and seasons with 162 games). For each player/year compute singles, doubles, triples, HR, BB per plate appearance rates. Create a new pandas DataFrame called `playerstats` that has the playerID, yearID and the rates of these stats.  Remove the average for each year as for these rates as done in Problem 1(e). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the head of the `playerstats` DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(h)\n",
    "\n",
    "Using the `playerstats` DataFrame created in Problem 1(g), create a new DataFrame called `playerLS` containing the player's lifetime stats. This DataFrame should contain the playerID, the year the player's career started, the year the player's career ended and the player's lifetime average for each of the quantities (singles, doubles, triples, HR, BB). For simplicity we will simply compute the avaerage of the rates by year (a more correct way is to go back to the totals). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the head of the `playerLS` DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(i)\n",
    "\n",
    "Compute the OPW for each player based on the average rates in the `playerLS` DataFrame. You can interpret this summary statistic as the predicted wins for a team with 9 batters exactly like the player in question. Add this column to the playerLS DataFrame. Call this colum OPW."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(j)\n",
    "\n",
    "Add four columns to the `playerLS` DataFrame that contains the player's position (C, 1B, 2B, 3B, SS, LF, CF, RF, or OF), first name, last name and median salary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the head of the `playerLS` DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(k)\n",
    "\n",
    "Subset the `playerLS` DataFrame for players active in 2002 and 2003 and played at least three years. Plot and describe the relationship bewteen the median salary (in millions) and the predicted number of wins. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(l)\n",
    "Pick one players from one of each of these 10 position C, 1B, 2B, 3B, SS, LF, CF, RF, DH, or OF keeping the total median salary of all 10 players below 20 million. Report their averaged predicted wins and total salary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1(m)\n",
    "What do these players outperform in? Singles, doubles, triples HR or BB?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion for Problem 1\n",
    "\n",
    "*Write a brief discussion of your conclusions to the questions and tasks above in 100 words or less.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2:  $k$-Nearest Neighbors and Cross Validation \n",
    "\n",
    "What is the optimal $k$ for predicting species using $k$-nearest neighbor classification \n",
    "on the four features provided by the iris dataset.\n",
    "\n",
    "In this problem you will get to know the famous iris data set, and use cross validation to select the optimal $k$ for a $k$-nearest neighbor classification. This problem set makes heavy use of the [sklearn](http://scikit-learn.org/stable/) library. In addition to Pandas, it is one of the most useful libraries for data scientists! After completing this homework assignment you will know all the basics to get started with your own machine learning projects in sklearn. \n",
    "\n",
    "Future lectures will give further background information on different classifiers and their specific strengths and weaknesses, but when you have the basics for sklearn down, changing the classifier will boil down to exchanging one to two lines of code.\n",
    "\n",
    "The data set is so popular, that sklearn provides an extra function to load it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "#load the iris data set\n",
    "iris = sklearn.datasets.load_iris()\n",
    "\n",
    "X = iris.data  \n",
    "Y = iris.target\n",
    "\n",
    "print X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(a) \n",
    "Split the data into a train and a test set. Use a random selection of 33% of the samples as test data. Sklearn provides the [`train_test_split`](http://scikit-learn.org/stable/modules/generated/sklearn.cross_validation.train_test_split.html) function for this purpose. Print the dimensions of all the train and test data sets you have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(b)\n",
    "\n",
    "Examine the data further by looking at the projections to the first two principal components of the data. Use the [`TruncatedSVD`](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.TruncatedSVD.html) function for this purpose, and create a scatter plot. Use the colors on the scatter plot to represent the different classes in the target data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(c) \n",
    "\n",
    "In the lecture we discussed how to use cross validation to estimate the optimal value for $k$ (the number of nearest neighbors to base the classification on). Use ***ten fold cross validation*** to estimate the optimal value for $k$ for the iris data set. \n",
    "\n",
    "**Note**: For your convenience sklearn does not only include the [KNN classifier](http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html), but also a [grid search function](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html#sklearn.grid_search.GridSearchCV). The function is called grid search, because if you have to optimize more than one parameter, it is common practice to define a range of possible values for each parameter. An exhaustive search then runs over the complete grid defined by all the possible parameter combinations. This can get very computation heavy, but luckily our KNN classifier only requires tuning of a single parameter for this problem set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(d)\n",
    "\n",
    "Visualize the result by plotting the score results versus values for $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that the grid search has indeed chosen the right parameter value for $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2(e)\n",
    "\n",
    "Test the performance of our tuned KNN classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion for Problem 2\n",
    "\n",
    "*Write a brief discussion of your conclusions to the questions and tasks above in 100 words or less.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: The Curse and Blessing of Higher Dimensions\n",
    "\n",
    "In this problem we will investigate the influence of higher dimensional spaces on the classification. The data set is again one of the standard data sets from sklearn. The [digits data set](http://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) is similar to the MNIST data set discussed in the lecture. The main difference is, that each digit is represented by an 8x8 pixel image patch, which is considerably smaller than the 28x28 pixels from MNIST. In addition, the gray values are restricted to 16 different values (4 bit), instead of 256 (8 bit) for MNIST. \n",
    "\n",
    "First we again load our data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1797, 64) (1797,)\n"
     ]
    }
   ],
   "source": [
    "digits = sklearn.datasets.load_digits()\n",
    "\n",
    "X = digits.data  \n",
    "Y = digits.target\n",
    "\n",
    "print X.shape, Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(a) \n",
    "\n",
    "Start with the same steps as in Problem 2. Split the data into train and test set. Use 33% of the samples as test data. Print the dimensions of all the train and test data sets you created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(b) \n",
    "\n",
    "Similar to Problem 2(b), create a scatter plot of the projections to the first two PCs.  Use the colors on the scatter plot to represent the different classes in the target data. How well can we separate the classes?\n",
    "\n",
    "**Hint**: Use a `Colormap` in matplotlib to represent the diferent classes in the target data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create individual scatter plots using only two classes at a time to explore which classes are most difficult to distinguish in terms of class separability.  You do not need to create scatter plots for all pairwise comparisons, but at least show one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give a brief interpretation of the scatter plot. Which classes look like hard to distinguish? Do both feature dimensions contribute to the class separability? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(c) \n",
    "\n",
    "Write a **ten-fold cross validation** to estimate the optimal value for $k$ for the digits data set. *However*, this time we are interested in the influence of the number of dimensions we project the data down as well. \n",
    "\n",
    "Extend the cross validation as done for the iris data set, to optimize $k$ for different dimensional projections of the data. Create a boxplot showing test scores for the optimal $k$ for each $d$-dimensional subspace with $d$ ranging from one to ten. The plot should have the scores on the y-axis and the different dimensions $d$ on the x-axis. You can use your favorite plot function for the boxplots. [Seaborn](http://web.stanford.edu/~mwaskom/software/seaborn/index.html) is worth having a look at though. It is a great library for statistical visualization and of course also comes with a [`boxplot`](http://web.stanford.edu/~mwaskom/software/seaborn/generated/seaborn.boxplot.html) function that has simple means for changing the labels on the x-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your cross validation and evaluation code here ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your boxplot code here ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a short interpretation of the generated plot, answering the following questions:\n",
    "\n",
    "* What trend do you see in the plot for increasing dimensions?\n",
    "\n",
    "* Why do you think this is happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3(d) \n",
    "\n",
    "**For AC209 Students**: Change the boxplot we generated above to also show the optimal value for $k$ chosen by the cross validation grid search. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Your code here ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a short interpretation answering the following questions:\n",
    "\n",
    "* Which trend do you observe for the optimal value of $k$?\n",
    "\n",
    "* Why do you think this is happening?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Your answer here: **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion for Problem 3\n",
    "\n",
    "*Write a brief discussion of your conclusions to the questions and tasks above in 100 words or less.*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions\n",
    "\n",
    "To submit your homework, create a folder named **lastname_firstinitial_hw#** and place your IPython notebooks, data files, and any other files in this folder. Your IPython Notebooks should be completely executed with the results visible in the notebook. We should not have to run any code.  Compress the folder (please use .zip compression) and submit to the CS109 dropbox in the appropriate folder. *If we cannot access your work because these directions are not followed correctly, we will not grade your work.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
